{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"18819 project - cv approach.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNZllkkIXZB8/4Jae5WwLKe"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Mbo_8gXfGDn","executionInfo":{"status":"ok","timestamp":1634226481763,"user_tz":240,"elapsed":24370,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}},"outputId":"81279751-98a7-4efd-a5b8-cbb0320c713c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"C9YZG3lnfSfF"},"source":["drive_path = '/content/drive/MyDrive/sem2/quantum computing/project'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WuJCsusOG64P"},"source":["Imports"]},{"cell_type":"code","metadata":{"id":"qIRZx806G5E7"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","import multiprocessing\n","import scipy.ndimage\n","import skimage\n","import sklearn.cluster\n","import scipy.spatial.distance\n","import os, time\n","import matplotlib.pyplot as plt\n","import random\n","from skimage import io\n","from keras.datasets import mnist \n","import math\n","from sklearn.preprocessing import normalize\n","from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KWVr-9kJHHmo"},"source":["Pre-processing [for Mnist dataset](https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"id":"LH0huhhmHHCW","executionInfo":{"status":"ok","timestamp":1634251634380,"user_tz":240,"elapsed":664,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}},"outputId":"d8f34faa-e6bd-4fc5-f550-a8f2480c6217"},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","datagen = ImageDataGenerator(featurewise_center=True,\n","                             featurewise_std_normalization=True)\n","og = X_train[1]\n","img = datagen.standardize(X_train[1])\n","operatedImage = np.float32(img) / 255\n","pts = get_harris_points(operatedImage)\n","for pt in range(len(pts[0])):\n","  operatedImage[pts[0][pt],pts[1][pt]] = 0\n","plt.imshow(operatedImage)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f83079a42d0>"]},"metadata":{},"execution_count":157},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ttituC1-Iz7y"},"source":["# Feature extraction"]},{"cell_type":"markdown","metadata":{"id":"N6PULI54X309"},"source":["Harris corner detector"]},{"cell_type":"code","metadata":{"id":"VbndKBQvIyty"},"source":["def get_harris_points(image,k=0.05):\n","    from skimage.color import rgb2gray\n","    from scipy import ndimage\n","\n","\n","    bw_img = rgb2gray(image)\n","    Ix = cv2.Sobel(bw_img,cv2.CV_64F,1,0,ksize=3)\n","    Iy = cv2.Sobel(bw_img,cv2.CV_64F,0,1,ksize=3)\n","    \n","    IxIx = scipy.ndimage.filters.gaussian_filter(Ix**2,sigma=1)\n","    IyIy = scipy.ndimage.filters.gaussian_filter(Iy**2,sigma=1)\n","    \n","    IxIy = scipy.ndimage.filters.gaussian_filter(Ix*Iy,sigma=1)\n","    \n","    height,width = bw_img.shape\n","    \n","    det = IxIx * IyIy - IxIy ** 2\n","    trace = IxIx + IyIy\n","    \n","    R = det - k * trace ** 2\n","    \n","    idx = np.argsort(R.ravel(),axis = None)\n","    idx = idx[-150:]\n","    \n","    points_of_interest = [[],[]]\n","    for id in idx:\n","        \n","        x = id // R.shape[1]\n","        y = id % R.shape[1]\n","        if R[x][y] >0:\n","            points_of_interest[0].append(x)\n","            points_of_interest[1].append(y)\n","    return points_of_interest\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkO367QZgh3Y","executionInfo":{"status":"ok","timestamp":1634245006656,"user_tz":240,"elapsed":55,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}},"outputId":"87d43f8d-9799-4e3e-ea4d-3392e7228b2e"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1]\n","[1 1 1]\n","[0 1 2]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Xa8-g74zX6j1"},"source":["filter responses"]},{"cell_type":"code","metadata":{"id":"OEvDYdqoX9tR"},"source":["def display_filter_responses(response_maps):\n","    '''\n","    Visualizes the filter response maps.\n","\n","    [input]\n","    * response_maps: a numpy.ndarray of shape (H, W, 3F)\n","    '''\n","\n","    fig = plt.figure(1)\n","\n","    for i in range(20):\n","        plt.subplot(5, 4, i+1)\n","        resp = response_maps[:, :, i]\n","        resp_min = resp.min(axis=(0, 1), keepdims=True)\n","        resp_max = resp.max(axis=(0, 1), keepdims=True)\n","        resp = (resp-resp_min)/(resp_max-resp_min)\n","        plt.imshow(resp, cmap = 'gray')\n","        plt.axis(\"off\")\n","\n","    plt.subplots_adjust(left=0.05,right=0.95,top=0.95,bottom=0.05,wspace=0.05,hspace=0.05)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EihiTvqWCxdc"},"source":["Applying different filers on images for edge calculation"]},{"cell_type":"code","metadata":{"id":"2VlrDsrTXbP5"},"source":["def extract_filter_responses(image):\n","    '''\n","    Extracts the filter responses for the given image.\n","\n","    [input]\n","    * image: numpy.ndarray of shape (H, W) \n","\n","    [output]\n","    * filter_responses: numpy.ndarray of shape (H, W, F)\n","    '''\n","\n","    image = image.astype('float')\n","    image[image<0.5] = 0\n","    filter_responses = []\n","    \n","    for scale in [1,2,4,8,8*np.sqrt(2)]:\n","        #(1) Gaussian, (2) Laplacian of Gaussian, (3) derivative of Gaussian in the  𝑥  direction, and (4) derivative of Gaussian in the  𝑦  direction.\n","        r = scipy.ndimage.gaussian_filter(image,scale)\n","        gaussian = np.dstack([r])\n","        \n","        r = scipy.ndimage.gaussian_laplace(image,scale)\n","        laplace = np.dstack([r])\n","        \n","        r = scipy.ndimage.filters.gaussian_filter(image,(scale,scale),(1,0))\n","        y_dir = np.dstack([r])\n","\n","        r = scipy.ndimage.filters.gaussian_filter(image,(scale,scale),(0,1))\n","        x_dir = np.dstack([r])\n","        \n","        if len(filter_responses) != 0:\n","            filter_responses = np.dstack([filter_responses, gaussian,laplace,x_dir,y_dir])\n","        else:\n","            filter_responses = np.dstack([gaussian,laplace,x_dir,y_dir])\n","    return filter_responses "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVk3iNPfC3z5"},"source":["Compare the image with filter responses and detect the common edge points"]},{"cell_type":"code","metadata":{"id":"NcJZlwm4YKU9"},"source":["def compute_dictionary_one_image(args):\n","    '''\n","    Extracts samples of the dictionary entries from an image. Use the the \n","    harris corner detector implmented from previous question to extract \n","    the point of interests. This should be a function run by a subprocess.\n","\n","    [input]\n","    * i: index of training image\n","    * image_path: image\n","\n","    [saved]\n","    * sampled_response: numpy.ndarray of shape (alpha, 3F)\n","    '''\n","    i, image = args\n","    if not os.path.isdir('tmp'):\n","        os.mkdir('tmp')\n","\n","    f_name = drive_path+'/tmp/%05d.npy' % i\n","\n","    harris_points = get_harris_points(image)\n","    filter_responses = extract_filter_responses(image)\n","    sampled_responses = np.zeros(( len(harris_points[0]),filter_responses.shape[2] ))\n","\n","    for i in range(len(harris_points[0])):\n","        y,x = harris_points[0][i], harris_points[1][i]\n","        for n in range(filter_responses.shape[2]):\n","            sampled_responses[i,n] = filter_responses[y,x,n]\n","    np.save(f_name,sampled_responses)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AKt5Wrl0BQEw"},"source":["---\n","\n","Training dataset processing\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"pV3VmRHE75VO"},"source":["def compute_dictionary(num_workers=2):\n","    '''\n","    Creates the dictionary of visual words by clustering using k-means.\n","\n","    [input]\n","    * num_workers: number of workers to process in parallel\n","\n","    [saved]\n","    * dictionary: numpy.ndarray of shape (K,F)\n","    '''\n","    # ----- TODO -----\n","    list_of_args = []\n","\n","    n_clusters = 8\n","\n","\n","    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","    num_images = len(X_train)\n","    datagen = ImageDataGenerator(featurewise_center=True,\n","                             featurewise_std_normalization=True)\n","\n","    for i in range(num_images):\n","        img = datagen.standardize(X_train[i])\n","        operatedImage = np.float32(img) / 255\n","        list_of_args.append([i, operatedImage])\n","\n","    with multiprocessing.Pool(num_workers) as p:\n","        p.map(compute_dictionary_one_image, list_of_args)\n","\n","    filter_responses = []\n","    for file_name in os.listdir(drive_path+'/tmp'):\n","        cur = np.load(drive_path+'/tmp/'+file_name)\n","        if len(filter_responses) == 0:\n","            filter_responses = cur\n","        else:\n","            filter_responses = np.vstack([filter_responses,cur])\n","\n","    kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters).fit(filter_responses)\n","    dictionary = kmeans.cluster_centers_ \n","    np.save(drive_path+'/dictionary.npy', dictionary)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FT7JAxP5D7DX"},"source":["# compute_dictionary(4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEjNZu8bjDIG"},"source":["# Histogram Generation"]},{"cell_type":"markdown","metadata":{"id":"c1xsdKv_jUCW"},"source":["\n","\n","---\n","Sptial Pyramid Matching\n"]},{"cell_type":"code","metadata":{"id":"1_k2kfE7kdU3"},"source":["def get_visual_words(image, dictionary):\n","    filter_responses = extract_filter_responses(image)\n","    h, w, F = filter_responses.shape\n","    \n","    wordMap = np.zeros((h,w))\n","    for y in range(h):\n","        for x in range(w):\n","            filters = np.array([filter_responses[y][x][n] for n in range(F)]) # 1* 3F\n","            dist = scipy.spatial.distance.cdist(dictionary,[filters],metric='euclidean')\n","            wordMap[y][x] = np.argmin(dist)\n","    return wordMap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ijpJw3ol1nq"},"source":["def get_feature_from_wordmap(wordmap, dict_size):\n","    wordmap = wordmap.flatten()\n","    hist = np.histogram(wordmap,range(dict_size+1),density=True)\n","    return hist[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LAPYhvNgUGE"},"source":["def get_feature_from_wordmap_SPM(wordmap, layer_num, dict_size):\n","    h, w = wordmap.shape\n","    L = layer_num - 1\n","    patch_width = math.floor(w / (2**L))\n","    patch_height = math.floor(h / (2**L))\n","    hist_all = np.zeros((dict_size,int((4**(L+1) - 1)/3)))\n","    weight,i = 4,0\n","    metadata = [( 0 , 1.0/weight )]\n","    while i < L:\n","        metadata.append( ( (metadata[-1][0]+ 4**i) , 1.0/weight ) )\n","        weight/=2\n","        i += 1\n","    for l in range(L,-1,-1):\n","        if l == L:\n","            step = 0\n","            h_step,w_step = int(h // 2**l), int(w // 2**l)\n","            for cur_h in range(0,h_step*2**l,h_step):\n","                for cur_w in range(0,w_step*2**l,w_step):\n","                    cur_word = wordmap[cur_h:cur_h+h_step ,cur_w:cur_w+w_step]\n","                    hist = get_feature_from_wordmap(cur_word,dict_size)\n","                    hist_all[:,metadata[l][0]+step] = hist\n","                    step += 1\n","        else:\n","            arr = np.array(range(4**(l+1))).reshape(2**(l+1),2**(l+1))\n","            arr += metadata[l+1][0]\n","            step = metadata[l][0]\n","            for h in range(0,arr.shape[0],2):\n","                for w in range(0,arr.shape[1],2):\n","                    cur = hist_all[:,arr[h:h+2,w:w+2].reshape(-1)]\n","                    hist_all[:,step] = np.sum(cur,axis=1)\n","                    step += 1\n","    for l in range(L+1):\n","        start_idx,weight = metadata[l]\n","        total_cols = 4**l\n","        hist_all[:,start_idx:start_idx+total_cols] *= weight\n","    \n","    hist_all = hist_all.ravel()\n","    normalized_v = normalize(hist_all[:,np.newaxis], axis=0,norm ='l1').ravel()\n","    return normalized_v\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zgXezgGjZvt"},"source":["Running threads to convert all images into histograms"]},{"cell_type":"code","metadata":{"id":"uOFZ41t0jS2r"},"source":["def get_image_feature(args):\n","    i, dictionary, layer_num, K,image = args\n","    wordmap = get_visual_words(image,dictionary)\n","    feature = get_feature_from_wordmap_SPM(wordmap, layer_num, K)\n","    return [i, feature]\n","\n","def build_recognition_system(num_workers=2):\n","    dictionary = np.load(drive_path+\"/dictionary.npy\")\n","    SPM_layer_num = 3\n","    K = dictionary.shape[0]\n","\n","    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","    labels = y_train\n","    num_images = len(X_train)\n","    # num_images = 2\n","    datagen = ImageDataGenerator(featurewise_center=True,\n","                             featurewise_std_normalization=True)\n","    list_of_args = []\n","    for i in range(num_images):\n","        img = datagen.standardize(X_train[i])\n","        operatedImage = np.float32(img) / 255\n","        list_of_args.append([i,dictionary,SPM_layer_num,K,operatedImage])\n","\n","    with multiprocessing.Pool(num_workers) as p:\n","        features = p.map(get_image_feature, list_of_args)\n","\n","\n","    ordered_features = [None]* (num_images)\n","    for entry in features:\n","      ordered_features[entry[0]] = entry[1]\n","    \n","    ordered_features = np.array(ordered_features)\n","        \n","    np.savez('trained_system.npz', features=ordered_features,\n","                                    labels=labels,\n","                                    dictionary=dictionary,\n","                                    SPM_layer_num=SPM_layer_num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwzWV9lPk8kd","executionInfo":{"status":"ok","timestamp":1634247479536,"user_tz":240,"elapsed":2344818,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}},"outputId":"fb7aabf8-e19c-461e-8023-27e0e8832d90"},"source":["# build_recognition_system()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n","/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"]}]},{"cell_type":"markdown","metadata":{"id":"pC2VKgmO0YqG"},"source":["# Prediction of test set"]},{"cell_type":"code","metadata":{"id":"poY7ZruI0_Fn"},"source":["def distance_to_set(word_hist, histograms):\n","    return np.sum(np.minimum(word_hist,histograms),axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3VnKX8bPlCan","executionInfo":{"status":"ok","timestamp":1634253907192,"user_tz":240,"elapsed":176,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}}},"source":["def helper_func(args):\n","    i, dictionary, layer_num, K, trained_features, train_labels,image = args\n","\n","    args2 = i, dictionary, layer_num, K,image\n","    feature = get_image_feature(args2)\n","    feature = np.array(feature[1])\n","    nearest_image_idx = np.argmax(distance_to_set(trained_features,feature))\n","    pred_label = train_labels[nearest_image_idx]\n","    return [i, pred_label, nearest_image_idx]\n","\n","\n","def evaluate_recognition_system(num_workers=2):\n","    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","    trained_system = np.load(\"trained_system.npz\")\n","    \n","    images = X_test\n","    test_labels = y_test\n","\n","    trained_features = trained_system['features']\n","    train_labels = trained_system['labels']\n","    dictionary = trained_system['dictionary']\n","    SPM_layer_num = trained_system['SPM_layer_num']\n","    SPM_layer_num = int(SPM_layer_num)\n","    K = dictionary.shape[0]\n","\n","    print(\"Trained features shape: \", trained_features.shape)\n","\n","    list_of_args = []\n","    num_images = len(images)\n","    # num_images = 2\n","    for i in range(num_images):\n","        list_of_args.append([i, dictionary, SPM_layer_num, K, trained_features, train_labels,images[i]])\n","    \n","    p = multiprocessing.Pool(num_workers)\n","    labels = p.map_async(helper_func, list_of_args)\n","\n","    while not labels.ready():\n","        print('pending '+str(labels._number_left * labels._chunksize))\n","        time.sleep(60)\n","\n","    labels = labels.get()\n","    ordered_labels = [None] * len(labels)\n","    for label in labels:\n","        ordered_labels[label[0]] = label[1]\n","    \n","    ordered_labels = np.array(ordered_labels, dtype=int)\n","    print(\"Predicted labels shape: \", ordered_labels.shape)\n","    conf_matrix = confusion_matrix(test_labels, ordered_labels)\n","    accuracy = np.sum(conf_matrix.diagonal())/conf_matrix.sum()\n","    np.save(\"./conf_matrix.npy\",conf_matrix)\n","    return conf_matrix, accuracy"],"execution_count":163,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQlqgLFh14qA","executionInfo":{"status":"ok","timestamp":1634253694866,"user_tz":240,"elapsed":1744477,"user":{"displayName":"VINAY PATIL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjubQSJy-K2U2JOmf1BiihKnEVf4XZB_LBnPkgCOsg=s64","userId":"18393386811810083386"}},"outputId":"8cb02abe-c3db-456f-900d-8dfa0ef2b77e"},"source":["evaluate_recognition_system()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trained features shape:  (60000, 168)\n","pending 10000\n","pending 10000\n","pending 10000\n","pending 10000\n","pending 10000\n","pending 10000\n","pending 10000\n","pending 7500\n","pending 7500\n","pending 7500\n","pending 7500\n","pending 7500\n","pending 7500\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 5000\n","pending 2500\n","pending 2500\n","pending 2500\n","pending 2500\n","pending 2500\n","pending 2500\n","pending 2500\n","pending 2500\n","Predicted labels shape:  (10000,)\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([[575,   0,   0,   0,   0, 405,   0,   0,   0,   0],\n","        [  0, 698,   0,   0,   0, 437,   0,   0,   0,   0],\n","        [  0,   0, 645,   0,   0, 387,   0,   0,   0,   0],\n","        [  0,   0,   0, 607,   0, 403,   0,   0,   0,   0],\n","        [  0,   0,   0,   0, 622, 360,   0,   0,   0,   0],\n","        [  0,   0,   0,   0,   0, 892,   0,   0,   0,   0],\n","        [  0,   0,   0,   0,   0, 365, 593,   0,   0,   0],\n","        [  0,   0,   0,   0,   0, 418,   0, 610,   0,   0],\n","        [  0,   0,   0,   0,   0, 404,   0,   0, 570,   0],\n","        [  0,   0,   0,   0,   0, 383,   0,   0,   0, 626]]), 0.6438)"]},"metadata":{},"execution_count":162}]},{"cell_type":"code","metadata":{"id":"ISfxME0h1-f8"},"source":[""],"execution_count":null,"outputs":[]}]}